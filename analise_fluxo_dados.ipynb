{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28d2a02",
   "metadata": {},
   "source": [
    "# Data engenearing workbook\n",
    "\n",
    "## Context:\n",
    "My holdstaker needs to menage data from he's clients. \n",
    "I recived a pendrive with two main pathes, containg data from clients\n",
    "Total archive first count:\n",
    "\n",
    "In path 'NF' all files has the same prefix 'NF'\n",
    "In path 'PlanilhaCorretores' file prefix are ['Presta√ß√£o de Contas', 'Planilha Comiss√£o']\n",
    "\n",
    "## Taks:\n",
    "### - Merge 'pdf' files from same client\n",
    "      - Identify and Extract client name in all prefix\n",
    "      - Join match files as Client Name.pdf\n",
    "\n",
    "### - Create a table containing information about clients: name, processNumber, situation, responsableOne, nf(bool)\n",
    "      - match = extract and compare name from prefix\n",
    "      - name = originalName, processNumber = (get originalName and processNumber from table in pdf file)\n",
    "      - situation,responsableOne = 'Planilha Comiss√£o 'Name' (situation, responsableOne)\n",
    "      - nf (for client in clients, if nf 'name' in nf[], return true, else, false)\n",
    "\n",
    "\n",
    "### - Create a table containing information about cliente in NF: name, nf_number, date  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6436e3",
   "metadata": {},
   "source": [
    "## 1 - Data Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9519aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Imports, Paths and Data Structures\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import sys\n",
    "\n",
    "\n",
    "PATH_NF = 'path_to_nf_files'\n",
    "PATH_PLANILHAS_PRESTACOES = 'path_to_planilhas_prestacoes'\n",
    "\n",
    "#data from NF\n",
    "nf_table = {\n",
    "    \"origem\": [],\n",
    "    \"nome_arquivo\": [],\n",
    "    \"nome\": [],\n",
    "    \"data\": [],\n",
    "    \"corretor\": [],\n",
    "    \"situa√ß√£o\": []\n",
    "}\n",
    "#data from Presta√ß√£o de Contas\n",
    "pr_table = {\n",
    "    \"origem\": [],\n",
    "    \"nome_arquivo\": [],\n",
    "    \"nome\": [],\n",
    "    \"nome_encontrado\": [],\n",
    "    \"n_processo\":[],\n",
    "}\n",
    "#data from Planilhas\n",
    "pl_table = {\n",
    "    \"origem\": [],\n",
    "    \"nome_arquivo\": [],\n",
    "    \"nome\": [],\n",
    "    \"corretor\": [],\n",
    "    \"situa√ß√£o\": []\n",
    "}\n",
    "#final data set - estrutura corrigida\n",
    "final_table = {\n",
    "    \"nome\": [],\n",
    "    \"origem_nf\": [],      # Lista de caminhos de NF para este cliente\n",
    "    \"origem_pl\": [],      # Lista de caminhos de Planilhas para este cliente\n",
    "    \"origem_pr\": [],      # Lista de caminhos de Presta√ß√µes para este cliente\n",
    "    \"data_nf\": [],        # Data da NF\n",
    "    \"n_processo\": [],     # N√∫mero do processo (da presta√ß√£o)\n",
    "    \"situa√ß√£o\": [],       # Situa√ß√£o (da planilha)\n",
    "    \"corretor\": [],       # Corretor (da planilha)\n",
    "    \"nome_encontrado\": [] # Nome encontrado no PDF da presta√ß√£o\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Populate nf_table, pr_table, pl_table with file_name and full paths\n",
    "\n",
    "for fullPath in [PATH_PLANILHAS_PRESTACOES, PATH_NF]:\n",
    "    for file in os.listdir(fullPath):\n",
    "        if file.lower().startswith('nf '):\n",
    "            nf_table[\"origem\"].append(fullPath + '\\\\' + file)\n",
    "            nf_table[\"nome_arquivo\"].append(file)\n",
    "        if file.lower().startswith('planilha'):\n",
    "            pl_table[\"origem\"].append(fullPath + '\\\\' + file)\n",
    "            pl_table[\"nome_arquivo\"].append(file)\n",
    "        if file.lower().startswith('presta√ß√£o'):\n",
    "            pr_table[\"origem\"].append(fullPath + '\\\\' + file)\n",
    "            pr_table[\"nome_arquivo\"].append(file)\n",
    "\n",
    "print('Resumo da An√°lise de Arquivos PDF:')\n",
    "print(f'Total de arquivos: {len(table[\"origem\"])}')\n",
    "print(f'Total de NF: {len(nf_table[\"origem\"])}')\n",
    "print(f'Total de Planilhas: {len(pl_table[\"origem\"])}')\n",
    "print(f'Total de Presta√ß√µes: {len(pr_table[\"origem\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Function to process names in all file_names as 'nome' , wich will be used as key for matching\n",
    "\n",
    "def processar_nome(nome):\n",
    "    nome = nome.title()\n",
    "\n",
    "    # Remove prefix \n",
    "    for prefix in ['Planilha Comiss√£o ', 'Presta√ß√£o De Contas ', 'Nf ']:\n",
    "        if nome.startswith(prefix.title()):\n",
    "            nome = nome.replace(prefix.title(), '')\n",
    "\n",
    "    # Remove sufix\n",
    "    nome = nome.replace('.Pdf', '')\n",
    "    nome = re.sub(r'\\s*\\(.*?\\)', '', nome).strip()\n",
    "\n",
    "    # Treating 'Esp√≥lio' cases\n",
    "    if nome.lower().startswith((\"esp√≥lio\", \"espolio\")):\n",
    "        nome = re.sub(r'^(Esp[√≥o]lio( De)?)\\s*', '', nome, flags=re.IGNORECASE)\n",
    "        nome = nome.strip() + \" - Esp√≥lio\"\n",
    "\n",
    "    return nome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411060fa",
   "metadata": {},
   "source": [
    "### 1.2 NF\n",
    "\n",
    "#### Colect nf emission date in open file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff44b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Try colect data from NF files (FAILED ATTEMPT)\n",
    "\n",
    "reader = PyPDF2.PdfReader(r\"D:\\Documentos\\JOBS\\DATA\\Relat√≥rioAndiappToledo\\Toledo 2025_Edit\\N Fiscais Toledo 2025\\NF Abrah√£o Sadigursky.pdf\")\n",
    "texto = \"\"\n",
    "for page in reader.pages:\n",
    "    texto += page.extract_text()\n",
    "if texto:\n",
    "    print(texto)\n",
    "else:\n",
    "    print(\"No text found in the PDF.\")\n",
    "\n",
    "# No return in text extraction\n",
    "# Suspecting that the PDF might be scanned images\n",
    "# Need to use OCR to extract text from images in PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 Try colect data from scanned PDF using OCR (SUCCESSFUL ATTEMPT)\n",
    "\n",
    "# Tesseract executable path\n",
    "TESSERACT_PATH = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH\n",
    "\n",
    "\n",
    "def extrair_texto_pdf_ocr(file):\n",
    "    texto_completo = \"\"\n",
    "    try:\n",
    "        # Abre o PDF\n",
    "        doc = fitz.open(file)\n",
    "        \n",
    "\n",
    "        for i, pagina in enumerate(doc):\n",
    "            # 1. Zoom para melhorar a qualidade da imagem para o OCR\n",
    "            zoom = 2 \n",
    "            matriz = fitz.Matrix(zoom, zoom)\n",
    "            pix = pagina.get_pixmap(matrix=matriz)\n",
    "            \n",
    "            # 2. Converte para imagem PIL\n",
    "            imagem = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # 3. Tenta fazer o OCR\n",
    "            try:\n",
    "                # Tenta ler em PORTUGU√äS primeiro\n",
    "                texto_pagina = pytesseract.image_to_string(imagem, lang='eng')\n",
    "            except pytesseract.TesseractError as e:\n",
    "                # Se der erro de \"language not found\", cai aqui\n",
    "                print(f\"\\nAviso: {e}. Tentando OCR em INGL√äS.\")\n",
    "\n",
    "            texto_completo += texto_pagina\n",
    "            \n",
    "\n",
    "        doc.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO CR√çTICO: {e}\")\n",
    "        print(\"\\nVerifique se o caminho na linha 9 est√° apontando para onde voc√™ instalou o Tesseract.\")\n",
    "\n",
    "    return texto_completo\n",
    "\n",
    "\n",
    "def extrair_data_texto(texto):\n",
    "    padrao_data = r\"Data e Hora de Emiss[√£a]o.*?:?\\s*\\\"?(\\d{2}/\\d{2}/\\d{4})\"\n",
    "    match = re.search(padrao_data, texto, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        return match.group(1)        \n",
    "    else:\n",
    "        print(\"N/A.\")\n",
    "        return None\n",
    "        \n",
    "\n",
    "    return data_encontrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d637c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Populate nf_table with key names anda extracted dates\n",
    "\n",
    "nf_table['nome'] = [processar_nome(n) for n in nf_table['nome_arquivo']]\n",
    "\n",
    "for o in nf_table['origem']:\n",
    "    texto = extrair_texto_pdf_ocr(o)\n",
    "    data = extrair_data_texto(texto)    \n",
    "    nf_table[\"data\"].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f179af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Display nf_table as DataFrame\n",
    "nf_df = pd.DataFrame(nf_table)\n",
    "nf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Display nf_table info\n",
    "nf_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5abd1",
   "metadata": {},
   "source": [
    "### 1.3 - Planilhas\n",
    "#### Colect 'Corretor' and 'Situa√ß√£o' in file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Colect data from file_name as 'texto'\n",
    "\n",
    "def extrair_situacao_corretor(texto):\n",
    "    \"\"\"\n",
    "    Extrai situa√ß√£o e corretor do formato: (Situa√ß√£o Nome_Corretor)\n",
    "    Exemplos: (VT Jo√£o Silva), (V Total Maria Santos)\n",
    "    \"\"\"\n",
    "\n",
    "    padrao = r'\\(\\s*(.+?)\\s{2,}(.+?)\\s*\\)|' \\\n",
    "             r'\\(\\s*([A-Z]+)\\s+([A-Z][^)]+)\\)'\n",
    "    \n",
    "    match = re.search(padrao, texto)\n",
    "    \n",
    "    if match:\n",
    "        # Tenta primeiro padr√£o (2+ espa√ßos separam)\n",
    "        if match.group(1) and match.group(2):\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "        # Se n√£o, usa segundo padr√£o (situa√ß√£o em caps + nome)\n",
    "        elif match.group(3) and match.group(4):\n",
    "            return match.group(3).strip(), match.group(4).strip()\n",
    "    \n",
    "    print(f\"Verificar formato em: {texto[:50]}...\")\n",
    "    return None, None\n",
    "\n",
    "def extrair_situacao(texto):\n",
    "    situacao, _ = extrair_situacao_corretor(texto)\n",
    "    return situacao\n",
    "\n",
    "def extrair_corretor(texto):\n",
    "    _, corretor = extrair_situacao_corretor(texto)\n",
    "    return corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Populate pl_table with key names, corretor and situa√ß√£o'\n",
    "pl_table['nome'] = [processar_nome(n) for n in pl_table['nome_arquivo']]\n",
    "pl_table['corretor'] = [extrair_corretor(t) for t in pl_table['origem']]\n",
    "pl_table['situa√ß√£o'] = [extrair_situacao(t) for t in pl_table['origem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d560eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Display pl_table as DataFrame\n",
    "pl_df = pd.DataFrame(pl_table)\n",
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Display pl_table info\n",
    "pl_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c6a8f",
   "metadata": {},
   "source": [
    "### 1.4 - Presta√ß√£o De Contas\n",
    "#### Colect 'n_processo', 'nome_encontrado' in open file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d51240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Extract data from Presta√ß√£o de Contas pdf files\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extrair_dados_prestacao(caminho_pdf):\n",
    "    \"\"\"Extrai nome do cliente e n√∫mero do processo de um arquivo PDF\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(caminho_pdf)\n",
    "        texto = ''.join([page.extract_text() or '' for page in reader.pages])\n",
    "\n",
    "        # Extrair nome do cliente\n",
    "        nome_match = re.search(r'√Ä\\s+([^\\n]+)', texto)\n",
    "        nome_cliente = nome_match.group(1).strip() if nome_match else \"Nome n√£o encontrado\"\n",
    "\n",
    "        # Extrair n√∫mero do processo (padr√µes variados)\n",
    "        processo_match = re.search(r'(?:Processo|N¬∞ Processo)[:\\s]*([\\d\\.\\-/]+)', texto, re.IGNORECASE)\n",
    "        numero_processo = processo_match.group(1).strip() if processo_match else \"N√∫mero n√£o encontrado\"\n",
    "\n",
    "        return nome_cliente, numero_processo\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {os.path.basename(caminho_pdf)}: {str(e)}\")\n",
    "        return \"Erro no processamento\", \"\"\n",
    "\n",
    "\n",
    "\n",
    "pr_table['nome'] = [processar_nome(n) for n in pr_table['nome']]\n",
    "pr_table['nome_encontrado'] = [extrair_dados_prestacao(o)[0] for o in pr_table['origem']]\n",
    "pr_table['n_processo'] = [extrair_dados_prestacao(o)[1] for o in pr_table['origem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b037bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Populate pr_table with key names, nome_encontrado and n_processo\n",
    "pr_table['nome'] = [processar_nome(n) for n in pr_table['nome']]\n",
    "pr_table['nome_encontrado'] = [extrair_dados_prestacao(o)[0] for o in pr_table['origem']]\n",
    "pr_table['n_processo'] = [extrair_dados_prestacao(o)[1] for o in pr_table['origem']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f950c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Display pr_table as DataFrame\n",
    "pr_df = pd.DataFrame(pr_table)\n",
    "pr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f11aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Display pr_table info\n",
    "pr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8a871",
   "metadata": {},
   "source": [
    "## Pipeline Final Table (Full Join)\n",
    "Join data from 3 tables in final relatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Set names\n",
    "todos_nomes = set()\n",
    "todos_nomes.update(nf_table['nome'])\n",
    "todos_nomes.update(pl_table['nome'])\n",
    "todos_nomes.update(pr_table['nome'])\n",
    "\n",
    "print(f\"Total de clientes √∫nicos encontrados: {len(todos_nomes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e15974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Group multiple origins by name\n",
    "from collections import defaultdict\n",
    "\n",
    "nf_por_nome = defaultdict(list)\n",
    "pl_por_nome = defaultdict(list)\n",
    "pr_por_nome = defaultdict(list)\n",
    "\n",
    "# Agrupar NF por nome\n",
    "for i, nome in enumerate(nf_table['nome']):\n",
    "    nf_por_nome[nome].append({\n",
    "        'origem': nf_table['origem'][i],\n",
    "        'data': nf_table['data'][i]\n",
    "    })\n",
    "\n",
    "# Agrupar Planilhas por nome\n",
    "for i, nome in enumerate(pl_table['nome']):\n",
    "    pl_por_nome[nome].append({\n",
    "        'origem': pl_table['origem'][i],\n",
    "        'corretor': pl_table['corretor'][i],\n",
    "        'situacao': pl_table['situa√ß√£o'][i]\n",
    "    })\n",
    "\n",
    "# Agrupar Presta√ß√µes por nome\n",
    "for i, nome in enumerate(pr_table['nome']):\n",
    "    pr_por_nome[nome].append({\n",
    "        'origem': pr_table['origem'][i],\n",
    "        'nome_encontrado': pr_table['nome_encontrado'][i],\n",
    "        'n_processo': pr_table['n_processo'][i]\n",
    "    })\n",
    "\n",
    "print(\"‚úì Agrupamento por nome conclu√≠do\")\n",
    "print(f\"  - Clientes com NF: {len(nf_por_nome)}\")\n",
    "print(f\"  - Clientes com Planilha: {len(pl_por_nome)}\")\n",
    "print(f\"  - Clientes com Presta√ß√£o: {len(pr_por_nome)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013921fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Construct final table with FULL JOIN\n",
    "\n",
    "for nome in sorted(todos_nomes):\n",
    "    # Adicionar nome\n",
    "    final_table['nome'].append(nome)\n",
    "    \n",
    "    # ===== ORIGENS NF =====\n",
    "    if nome in nf_por_nome:\n",
    "        # M√∫ltiplas NFs: adiciona lista de caminhos\n",
    "        origens_nf = [nf['origem'] for nf in nf_por_nome[nome]]\n",
    "        final_table['origem_nf'].append(origens_nf)\n",
    "        \n",
    "        # Data: pega da primeira NF (ou voc√™ pode concatenar todas)\n",
    "        final_table['data_nf'].append(nf_por_nome[nome][0]['data'])\n",
    "    else:\n",
    "        final_table['origem_nf'].append(['Arquivo NF n√£o encontrado'])\n",
    "        final_table['data_nf'].append(None)\n",
    "    \n",
    "    # ===== ORIGENS PLANILHA =====\n",
    "    if nome in pl_por_nome:\n",
    "        # M√∫ltiplas planilhas: adiciona lista de caminhos\n",
    "        origens_pl = [pl['origem'] for pl in pl_por_nome[nome]]\n",
    "        final_table['origem_pl'].append(origens_pl)\n",
    "        \n",
    "        # Situa√ß√£o e Corretor: pega da primeira (ou voc√™ pode verificar se s√£o iguais)\n",
    "        final_table['situa√ß√£o'].append(pl_por_nome[nome][0]['situacao'])\n",
    "        final_table['corretor'].append(pl_por_nome[nome][0]['corretor'])\n",
    "    else:\n",
    "        final_table['origem_pl'].append(['Arquivo Planilha n√£o encontrado'])\n",
    "        final_table['situa√ß√£o'].append('Situa√ß√£o n√£o encontrada')\n",
    "        final_table['corretor'].append('Corretor n√£o encontrado')\n",
    "    \n",
    "    # ===== ORIGENS PRESTA√á√ÉO =====\n",
    "    if nome in pr_por_nome:\n",
    "        # M√∫ltiplas presta√ß√µes: adiciona lista de caminhos\n",
    "        origens_pr = [pr['origem'] for pr in pr_por_nome[nome]]\n",
    "        final_table['origem_pr'].append(origens_pr)\n",
    "        \n",
    "        # Processo e nome encontrado: pega do primeiro\n",
    "        final_table['n_processo'].append(pr_por_nome[nome][0]['n_processo'])\n",
    "        final_table['nome_encontrado'].append(pr_por_nome[nome][0]['nome_encontrado'])\n",
    "    else:\n",
    "        final_table['origem_pr'].append(['Arquivo Presta√ß√£o n√£o encontrado'])\n",
    "        final_table['n_processo'].append('Processo n√£o encontrado')\n",
    "        final_table['nome_encontrado'].append('Verificar presta√ß√£o')\n",
    "\n",
    "print(f\"\\n‚úì Tabela final constru√≠da com {len(final_table['nome'])} clientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASSO 4: Visualizar resumo e verificar inconsist√™ncias\n",
    "\n",
    "# Converter para DataFrame para facilitar an√°lise\n",
    "df_final = pd.DataFrame(final_table)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESUMO DA TABELA FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal de clientes: {len(df_final)}\")\n",
    "print(f\"\\nDimens√µes: {df_final.shape}\")\n",
    "print(f\"\\nColunas: {list(df_final.columns)}\")\n",
    "\n",
    "# Estat√≠sticas de arquivos faltantes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AN√ÅLISE DE ARQUIVOS FALTANTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nf_faltantes = df_final[df_final['origem_nf'].apply(lambda x: 'n√£o encontrado' in str(x).lower())]\n",
    "pl_faltantes = df_final[df_final['origem_pl'].apply(lambda x: 'n√£o encontrado' in str(x).lower())]\n",
    "pr_faltantes = df_final[df_final['origem_pr'].apply(lambda x: 'n√£o encontrado' in str(x).lower())]\n",
    "\n",
    "print(f\"\\nüìÑ Clientes SEM NF: {len(nf_faltantes)}\")\n",
    "print(f\"üìÑ Clientes SEM Planilha: {len(pl_faltantes)}\")\n",
    "print(f\"üìÑ Clientes SEM Presta√ß√£o: {len(pr_faltantes)}\")\n",
    "\n",
    "# Clientes com m√∫ltiplos arquivos\n",
    "multiplos_nf = df_final[df_final['origem_nf'].apply(lambda x: isinstance(x, list) and len(x) > 1 and 'n√£o encontrado' not in str(x).lower())]\n",
    "multiplos_pl = df_final[df_final['origem_pl'].apply(lambda x: isinstance(x, list) and len(x) > 1 and 'n√£o encontrado' not in str(x).lower())]\n",
    "multiplos_pr = df_final[df_final['origem_pr'].apply(lambda x: isinstance(x, list) and len(x) > 1 and 'n√£o encontrado' not in str(x).lower())]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLIENTES COM M√öLTIPLOS ARQUIVOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìë Clientes com >1 NF: {len(multiplos_nf)}\")\n",
    "if len(multiplos_nf) > 0:\n",
    "    print(\"   Exemplos:\")\n",
    "    for idx in multiplos_nf.head(3).index:\n",
    "        print(f\"   - {df_final.loc[idx, 'nome']}: {len(df_final.loc[idx, 'origem_nf'])} arquivos\")\n",
    "\n",
    "print(f\"\\nüìë Clientes com >1 Planilha: {len(multiplos_pl)}\")\n",
    "if len(multiplos_pl) > 0:\n",
    "    print(\"   Exemplos:\")\n",
    "    for idx in multiplos_pl.head(3).index:\n",
    "        print(f\"   - {df_final.loc[idx, 'nome']}: {len(df_final.loc[idx, 'origem_pl'])} arquivos\")\n",
    "\n",
    "print(f\"\\nüìë Clientes com >1 Presta√ß√£o: {len(multiplos_pr)}\")\n",
    "if len(multiplos_pr) > 0:\n",
    "    print(\"   Exemplos:\")\n",
    "    for idx in multiplos_pr.head(3).index:\n",
    "        print(f\"   - {df_final.loc[idx, 'nome']}: {len(df_final.loc[idx, 'origem_pr'])} arquivos\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRIMEIRAS 10 LINHAS DA TABELA\")\n",
    "print(\"=\"*60)\n",
    "print(df_final.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a555e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASSO 5: Exportar tabela final para CSV/Excel\n",
    "\n",
    "OUTPUT_FOLDER = r\"D:\\Documentos\\JOBS\\DATA\\Relat√≥rioAndiappToledo\\Dados\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Exportar CSV\n",
    "csv_path = os.path.join(OUTPUT_FOLDER, \"tabela_final_clientes.csv\")\n",
    "df_final.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"‚úì CSV exportado: {csv_path}\")\n",
    "\n",
    "# Exportar Excel (com formata√ß√£o melhor para listas)\n",
    "excel_path = os.path.join(OUTPUT_FOLDER, \"tabela_final_clientes.xlsx\")\n",
    "\n",
    "# Converter listas para strings para visualiza√ß√£o no Excel\n",
    "df_export = df_final.copy()\n",
    "for col in ['origem_nf', 'origem_pl', 'origem_pr']:\n",
    "    df_export[col] = df_export[col].apply(lambda x: '\\n'.join(x) if isinstance(x, list) else str(x))\n",
    "\n",
    "df_export.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "print(f\"‚úì Excel exportado: {excel_path}\")\n",
    "\n",
    "# Gerar relat√≥rios de clientes faltantes\n",
    "relatorio_faltantes = {\n",
    "    'nome': [],\n",
    "    'falta_nf': [],\n",
    "    'falta_pl': [],\n",
    "    'falta_pr': [],\n",
    "    'total_faltantes': []\n",
    "}\n",
    "\n",
    "for idx, row in df_final.iterrows():\n",
    "    falta_nf = 'n√£o encontrado' in str(row['origem_nf']).lower()\n",
    "    falta_pl = 'n√£o encontrado' in str(row['origem_pl']).lower()\n",
    "    falta_pr = 'n√£o encontrado' in str(row['origem_pr']).lower()\n",
    "    \n",
    "    total_faltantes = sum([falta_nf, falta_pl, falta_pr])\n",
    "    \n",
    "    if total_faltantes > 0:  # S√≥ adiciona se faltar algo\n",
    "        relatorio_faltantes['nome'].append(row['nome'])\n",
    "        relatorio_faltantes['falta_nf'].append('SIM' if falta_nf else 'N√ÉO')\n",
    "        relatorio_faltantes['falta_pl'].append('SIM' if falta_pl else 'N√ÉO')\n",
    "        relatorio_faltantes['falta_pr'].append('SIM' if falta_pr else 'N√ÉO')\n",
    "        relatorio_faltantes['total_faltantes'].append(total_faltantes)\n",
    "\n",
    "df_faltantes = pd.DataFrame(relatorio_faltantes)\n",
    "faltantes_path = os.path.join(OUTPUT_FOLDER, \"clientes_arquivos_faltantes.xlsx\")\n",
    "df_faltantes.to_excel(faltantes_path, index=False, engine='openpyxl')\n",
    "print(f\"‚úì Relat√≥rio de faltantes exportado: {faltantes_path}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EXPORTA√á√ÉO CONCLU√çDA!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NF Relatory - Match corretor and situa√ß√£o from pl_table to nf_table else return none\n",
    "\n",
    "for nf in nf_table['nome']:\n",
    "    encontrado = False\n",
    "    for i, pl in enumerate(pl_table['nome']):\n",
    "        if nf == pl:\n",
    "            nf_table['corretor'].append(pl_table['corretor'][i])\n",
    "            nf_table['situa√ß√£o'].append(pl_table['situa√ß√£o'][i])\n",
    "            encontrado = True            \n",
    "            break\n",
    "    if not encontrado:\n",
    "        nf_table['corretor'].append(None)\n",
    "\n",
    "for k, v in nf_table.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d227a9",
   "metadata": {},
   "source": [
    "# PDF Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Check empty pages in each PDF in a folder and offer to delete them\n",
    "\n",
    "def analisar_e_limpar_pdfs(caminho_da_pasta):\n",
    "    \"\"\"\n",
    "    Analisa todos os arquivos PDF em uma pasta, relata suas propriedades\n",
    "    e oferece a op√ß√£o de remover p√°ginas em branco.\n",
    "    Filtra o relat√≥rio para exibir apenas arquivos com mais de uma p√°gina.\n",
    "\n",
    "    Args:\n",
    "        caminho_da_pasta (str): O caminho para a pasta contendo os arquivos PDF.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(caminho_da_pasta):\n",
    "        print(f\"Erro: O caminho '{caminho_da_pasta}' n√£o √© uma pasta v√°lida.\")\n",
    "        return\n",
    "\n",
    "    # --- ESTRUTURAS DE DADOS PARA ARMAZENAR OS RESULTADOS ---\n",
    "    relatorio_paginas = {}\n",
    "    total_paginas_por_arquivo = {} # Dicion√°rio auxiliar para guardar o total de p√°ginas\n",
    "    arquivos_com_mais_de_uma_pagina = 0\n",
    "    arquivos_com_paginas_em_branco = {}\n",
    "\n",
    "    print(f\"--- Iniciando An√°lise da Pasta: {caminho_da_pasta} ---\\n\")\n",
    "\n",
    "    lista_de_arquivos = [f for f in os.listdir(caminho_da_pasta) if f.lower().endswith('.pdf')]\n",
    "\n",
    "    if not lista_de_arquivos:\n",
    "        print(\"Nenhum arquivo PDF encontrado na pasta.\")\n",
    "        return\n",
    "\n",
    "    # --- FASE 1: AN√ÅLISE DOS ARQUIVOS ---\n",
    "    for nome_arquivo in lista_de_arquivos:\n",
    "        caminho_completo = os.path.join(caminho_da_pasta, nome_arquivo)\n",
    "        \n",
    "        try:\n",
    "            doc = fitz.open(caminho_completo)\n",
    "            total_paginas = doc.page_count\n",
    "            total_paginas_por_arquivo[nome_arquivo] = total_paginas # Armazena o total\n",
    "            paginas_em_branco_indices = []\n",
    "            \n",
    "            # Verifica se o arquivo tem mais de uma p√°gina\n",
    "            if total_paginas > 1:\n",
    "                arquivos_com_mais_de_uma_pagina += 1\n",
    "\n",
    "            # Itera por cada p√°gina para an√°lise\n",
    "            for i in range(total_paginas):\n",
    "                page = doc.load_page(i)\n",
    "                # Crit√©rio de p√°gina em branco: n√£o tem texto e n√£o tem imagens.\n",
    "                if not page.get_text() and not page.get_images():\n",
    "                    paginas_em_branco_indices.append(i)\n",
    "\n",
    "            # Armazena a contagem de p√°ginas que atendem ao crit√©rio (n√£o est√£o em branco)\n",
    "            paginas_validas = total_paginas - len(paginas_em_branco_indices)\n",
    "            relatorio_paginas[nome_arquivo] = paginas_validas\n",
    "            \n",
    "            # Se encontrou p√°ginas em branco, armazena quais s√£o\n",
    "            if paginas_em_branco_indices:\n",
    "                arquivos_com_paginas_em_branco[nome_arquivo] = [p + 1 for p in paginas_em_branco_indices]\n",
    "\n",
    "            doc.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"N√£o foi poss√≠vel processar o arquivo '{nome_arquivo}'. Erro: {e}\")\n",
    "\n",
    "    # --- FASE 2: APRESENTA√á√ÉO DOS RESULTADOS (COM FILTRO) ---\n",
    "    print(\"--- Relat√≥rio da An√°lise Conclu√≠do ---\\n\")\n",
    "    \n",
    "    # MODIFICA√á√ÉO AQUI: Adicionado filtro para mostrar apenas arquivos com mais de 1 p√°gina\n",
    "    print(\"1. Quantidade de p√°ginas v√°lidas (n√£o-brancas) por arquivo (somente arquivos com >1 p√°gina):\")\n",
    "    if relatorio_paginas:\n",
    "        arquivos_filtrados_exibidos = False\n",
    "        for nome, qtd in relatorio_paginas.items():\n",
    "            # A condi√ß√£o do filtro √© aplicada aqui\n",
    "            if total_paginas_por_arquivo.get(nome, 0) > 1:\n",
    "                print(f\"  - {nome}: {qtd} p√°gina(s)\")\n",
    "                arquivos_filtrados_exibidos = True\n",
    "        if not arquivos_filtrados_exibidos:\n",
    "             print(\"  Nenhum arquivo com mais de uma p√°gina foi encontrado para listar.\")\n",
    "    else:\n",
    "        print(\"  Nenhum arquivo processado.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(f\"2. Total de arquivos com mais de uma p√°gina: {arquivos_com_mais_de_uma_pagina}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\"3. Arquivos que cont√™m p√°ginas em branco:\")\n",
    "    if arquivos_com_paginas_em_branco:\n",
    "        for nome, paginas in arquivos_com_paginas_em_branco.items():\n",
    "            print(f\"  - {nome} (P√°ginas em branco: {paginas})\")\n",
    "    else:\n",
    "        print(\"  Nenhum arquivo com p√°ginas em branco foi encontrado.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"\\n--- Verifica√ß√£o Manual Completa ---\")\n",
    "\n",
    "\n",
    "    print(\"\\n-- AN√ÅLISE ---\\n\")\n",
    "    print(\"Os arquivos com mais de uma p√°gina listados acima cont√™m informa√ß√µes v√°lidas.\")\n",
    "    print(\"Os demais arquivos foram limpos de p√°ginas em branco, se houveram.\")\n",
    "    \n",
    "    # --- FASE 3: A√á√ÉO DE APAGAR P√ÅGINAS (COM CONFIRMA√á√ÉO) ---\n",
    "    if not arquivos_com_paginas_em_branco:\n",
    "        print(\"\\nProcesso finalizado. Nenhuma a√ß√£o de modifica√ß√£o necess√°ria.\")\n",
    "        return\n",
    "\n",
    "    prosseguir = input(\"\\nDeseja apagar as p√°ginas em branco listadas acima? (s/n): \").lower()\n",
    "\n",
    "    if prosseguir == 's':\n",
    "        print(\"\\n--- Iniciando a remo√ß√£o de p√°ginas em branco ---\")\n",
    "        \n",
    "        pasta_saida = os.path.join(caminho_da_pasta, \"arquivos_limpos\")\n",
    "        os.makedirs(pasta_saida, exist_ok=True)\n",
    "        print(f\"Os arquivos modificados ser√£o salvos em: '{pasta_saida}'\")\n",
    "\n",
    "        for nome_arquivo, paginas in arquivos_com_paginas_em_branco.items():\n",
    "            try:\n",
    "                caminho_original = os.path.join(caminho_da_pasta, nome_arquivo)\n",
    "                doc = fitz.open(caminho_original)\n",
    "                \n",
    "                indices_para_remover = sorted([p - 1 for p in paginas], reverse=True)\n",
    "                \n",
    "                for indice in indices_para_remover:\n",
    "                    doc.delete_page(indice)\n",
    "                \n",
    "                caminho_novo_arquivo = os.path.join(pasta_saida, nome_arquivo)\n",
    "                doc.save(caminho_novo_arquivo, garbage=4, deflate=True)\n",
    "                doc.close()\n",
    "                print(f\"  - P√°ginas removidas de '{nome_arquivo}'. Nova vers√£o salva.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  - Erro ao modificar o arquivo '{nome_arquivo}': {e}\")\n",
    "        \n",
    "        print(\"\\n--- Processo de limpeza conclu√≠do! ---\")\n",
    "    else:\n",
    "        print(\"\\nNenhuma modifica√ß√£o foi realizada. Processo encerrado.\")\n",
    "\n",
    "\n",
    "# --- COMO USAR O SCRIPT ---\n",
    "if __name__ == \"__main__\":\n",
    "    # IMPORTANTE: Substitua o caminho abaixo pela pasta onde est√£o seus PDFs.\n",
    "    pasta_de_pdfs = \"D:\\Documentos\\PyCharmD\\.venv\\Projetos 2025\\Servi√ßoAnddiapToledo\\Toledo 2025_Edit\\Planilha Corretores 2025\"\n",
    "    \n",
    "    analisar_e_limpar_pdfs(pasta_de_pdfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Delete empty pages in each individual file in each directory\n",
    "\n",
    "def apagar_ultima_pagina(diretorio, nome_arquivo):\n",
    "    \"\"\"\n",
    "    Remove a √∫ltima p√°gina de um arquivo PDF espec√≠fico.\n",
    "    Este m√©todo usa um arquivo tempor√°rio para garantir a compatibilidade e seguran√ßa,\n",
    "    evitando o erro de \"salvamento incremental\".\n",
    "    \"\"\"\n",
    "    caminho_completo = os.path.join(diretorio, nome_arquivo)\n",
    "    \n",
    "    # Define um nome para o arquivo tempor√°rio\n",
    "    nome_temp = os.path.join(diretorio, \"temp_\" + nome_arquivo)\n",
    "\n",
    "    # --- Verifica√ß√µes de Seguran√ßa ---\n",
    "    if not os.path.isfile(caminho_completo):\n",
    "        print(f\"\\nERRO: O arquivo '{nome_arquivo}' n√£o foi encontrado no diret√≥rio especificado.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Abre o documento PDF original\n",
    "        doc = fitz.open(caminho_completo)\n",
    "\n",
    "        total_paginas = doc.page_count\n",
    "        \n",
    "        if total_paginas <= 1:\n",
    "            print(f\"\\nAVISO: O arquivo '{nome_arquivo}' possui apenas uma p√°gina. Nenhuma a√ß√£o foi tomada.\")\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "        print(f\"\\nProcessando '{nome_arquivo}'...\")\n",
    "        print(f\"O arquivo possui {total_paginas} p√°ginas. A √∫ltima p√°gina (n¬∫ {total_paginas}) ser√° removida.\")\n",
    "\n",
    "        # Remove a √∫ltima p√°gina\n",
    "        doc.delete_page(total_paginas - 1)\n",
    "\n",
    "        # --- NOVA L√ìGICA DE SALVAMENTO ---\n",
    "        # 1. Salva as altera√ß√µes em um novo arquivo tempor√°rio\n",
    "        doc.save(nome_temp, garbage=4, deflate=True)\n",
    "        doc.close() # Fecha o documento original\n",
    "\n",
    "        # 2. Remove o arquivo original antigo\n",
    "        os.remove(caminho_completo)\n",
    "\n",
    "        # 3. Renomeia o arquivo tempor√°rio para o nome do original\n",
    "        os.rename(nome_temp, caminho_completo)\n",
    "\n",
    "        print(f\"\\nSUCESSO! A √∫ltima p√°gina do arquivo '{nome_arquivo}' foi removida.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERRO: Ocorreu um problema ao processar o arquivo '{nome_arquivo}': {e}\")\n",
    "        # Se um erro ocorrer, verifica se um arquivo tempor√°rio ficou para tr√°s e o remove\n",
    "        if os.path.exists(nome_temp):\n",
    "            os.remove(nome_temp)\n",
    "\n",
    "\n",
    "# --- PONTO DE EXECU√á√ÉO PRINCIPAL ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. CONFIGURE O DIRET√ìRIO AQUI\n",
    "    # IMPORTANTE: Substitua o caminho abaixo pelo caminho ABSOLUTO da pasta dos seus PDFs.\n",
    "    # Exemplo Windows: dir = \"C:\\\\Users\\\\SeuUsuario\\\\Desktop\\\\Meus Documentos\"\n",
    "    # Exemplo Linux/Mac: dir = \"/home/seu_usuario/documentos/pdfs_para_limpar\"\n",
    "    dir = r\"D:\\Documentos\\PyCharmD\\.venv\\Projetos 2025\\Servi√ßoAnddiapToledo\\Toledo 2025_Edit\\Planilha Corretores 2025\"\n",
    "    \n",
    "    # Verifica se o caminho foi alterado\n",
    "    if \"coloque/o/caminho\" in dir:\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(\"!!! ATEN√á√ÉO: Voc√™ precisa editar o script e configurar a     !!!\")\n",
    "        print(\"!!! vari√°vel 'dir' com o caminho para a sua pasta de PDFs.  !!!\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    else:\n",
    "        # 2. PE√áA PARA O USU√ÅRIO INFORMAR O NOME DO ARQUIVO\n",
    "        print(\"--- Ferramenta para Remover a √öltima P√°gina de um PDF ---\")\n",
    "        print(f\"Procurando arquivos no diret√≥rio: {dir}\")\n",
    "        print(\"AVISO: Esta a√ß√£o ir√° modificar o arquivo original. Tenha um backup.\\n\")\n",
    "        \n",
    "        nome_do_arquivo = input(\"Informe o nome do arquivo PDF (ex: relatorio.pdf): \")\n",
    "\n",
    "        # 3. CHAME A FUN√á√ÉO PARA FAZER A LIMPEZA\n",
    "        if nome_do_arquivo:\n",
    "            apagar_ultima_pagina(dir, nome_do_arquivo)\n",
    "        else:\n",
    "            print(\"Nenhum nome de arquivo foi inserido. Encerrando o programa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Merge cleaned PDFs per client\n",
    "\n",
    "# Definir pasta de destino\n",
    "PASTA_DESTINO = r\"OUTPUT\"\n",
    "os.makedirs(PASTA_DESTINO, exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INICIANDO MESCLAGEM DE PDFs POR CLIENTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "contador_sucesso = 0\n",
    "contador_erro = 0\n",
    "clientes_com_erro = []\n",
    "\n",
    "for idx, row in df_final.iterrows():\n",
    "    nome_cliente = row['nome']\n",
    "    \n",
    "    try:\n",
    "        merger = PyPDF2.PdfMerger()\n",
    "        arquivos_adicionados = 0\n",
    "        \n",
    "        # ORDEM: 1. Presta√ß√£o, 2. Planilha, 3. NF\n",
    "        ordem_merge = [\n",
    "            ('Presta√ß√£o', row['origem_pr']),\n",
    "            ('Planilha', row['origem_pl']),\n",
    "            ('NF', row['origem_nf'])\n",
    "        ]\n",
    "        \n",
    "        for tipo, origens in ordem_merge:\n",
    "            # Verificar se n√£o √© arquivo faltante\n",
    "            if isinstance(origens, list) and 'n√£o encontrado' not in str(origens).lower():\n",
    "                # Adicionar todos os arquivos deste tipo (suporta m√∫ltiplos)\n",
    "                for origem in origens:\n",
    "                    if os.path.exists(origem):\n",
    "                        merger.append(origem)\n",
    "                        arquivos_adicionados += 1\n",
    "                        print(f\"  ‚úì {tipo}: {os.path.basename(origem)}\")\n",
    "                    else:\n",
    "                        print(f\"  ‚ö† {tipo}: arquivo n√£o existe - {origem}\")\n",
    "        \n",
    "        # S√≥ salvar se adicionou pelo menos um arquivo\n",
    "        if arquivos_adicionados > 0:\n",
    "            caminho_saida = os.path.join(PASTA_DESTINO, f\"{nome_cliente}.pdf\")\n",
    "            merger.write(caminho_saida)\n",
    "            merger.close()\n",
    "            print(f\"‚úì PDF mesclado criado: {nome_cliente}.pdf ({arquivos_adicionados} arquivos)\\n\")\n",
    "            contador_sucesso += 1\n",
    "        else:\n",
    "            print(f\"‚ö† Nenhum arquivo encontrado para {nome_cliente} - PDF n√£o criado\\n\")\n",
    "            clientes_com_erro.append(nome_cliente)\n",
    "            contador_erro += 1\n",
    "            merger.close()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERRO ao processar {nome_cliente}: {e}\\n\")\n",
    "        clientes_com_erro.append(nome_cliente)\n",
    "        contador_erro += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14194c",
   "metadata": {},
   "source": [
    "# Final Relatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RESUMO DA MESCLAGEM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úì PDFs criados com sucesso: {contador_sucesso}\")\n",
    "print(f\"‚ùå Clientes com erro/sem arquivos: {contador_erro}\")\n",
    "print(f\"\\nPasta de destino: {PASTA_DESTINO}\")\n",
    "\n",
    "if clientes_com_erro:\n",
    "    print(f\"\\n‚ö† Clientes que n√£o geraram PDF:\")\n",
    "    for cliente in clientes_com_erro[:10]:  # Mostrar primeiros 10\n",
    "        print(f\"  - {cliente}\")\n",
    "    if len(clientes_com_erro) > 10:\n",
    "        print(f\"  ... e mais {len(clientes_com_erro) - 10} clientes\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
